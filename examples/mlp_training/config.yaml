# MLP Training on CIFAR-10 with maxP

seed: 42
n_steps: 10000
n_val_steps: 32
log_freq: 1
val_freq: 100
compile: true
device: "auto"

model:
  input_dim: 3072
  hidden_dim: 512
  n_layers: 4
  output_dim: 10
  bias: false

optimizer:
  type: "adam"
  lr_prefactor: 0.001

maxp:
  use_maxp: true
  parametrization: "mup"
  alignment: "full"
  warmup_steps: 100
  solve_interval: 1
  alignment_norm: "rms"

data:
  batch_size: 128
  num_workers: 4

logging:
  output_dir: "outputs/mlp_maxp"
  save_model: true
